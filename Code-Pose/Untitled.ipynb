{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89704af-3274-42ed-9528-ac18e91f0058",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a9ae309-e634-40af-9baf-1c1ab3dc20bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO \n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a8bdb93-6625-41ec-a871-18bfe97dc589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************\n",
      "<_io.BufferedReader name='yolov8n-pose.pt'>\n",
      "*******************************************\n",
      "\n",
      "0: 480x640 1 person, 179.9ms\n",
      "Speed: 5.7ms preprocess, 179.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 199.1ms\n",
      "Speed: 5.2ms preprocess, 199.1ms inference, 4.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 194.4ms\n",
      "Speed: 4.1ms preprocess, 194.4ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 165.2ms\n",
      "Speed: 4.5ms preprocess, 165.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 164.2ms\n",
      "Speed: 1.6ms preprocess, 164.2ms inference, 17.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 168.9ms\n",
      "Speed: 3.1ms preprocess, 168.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 154.2ms\n",
      "Speed: 1.5ms preprocess, 154.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 158.1ms\n",
      "Speed: 3.6ms preprocess, 158.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 140.1ms\n",
      "Speed: 2.3ms preprocess, 140.1ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 164.7ms\n",
      "Speed: 0.0ms preprocess, 164.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 168.8ms\n",
      "Speed: 3.0ms preprocess, 168.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 177.8ms\n",
      "Speed: 0.0ms preprocess, 177.8ms inference, 6.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 182.3ms\n",
      "Speed: 1.0ms preprocess, 182.3ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 174.2ms\n",
      "Speed: 2.0ms preprocess, 174.2ms inference, 7.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 200.6ms\n",
      "Speed: 3.0ms preprocess, 200.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 180.8ms\n",
      "Speed: 1.3ms preprocess, 180.8ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 172.7ms\n",
      "Speed: 2.2ms preprocess, 172.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 190.3ms\n",
      "Speed: 3.5ms preprocess, 190.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 176.5ms\n",
      "Speed: 2.0ms preprocess, 176.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 180.4ms\n",
      "Speed: 2.6ms preprocess, 180.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 176.2ms\n",
      "Speed: 0.0ms preprocess, 176.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 175.6ms\n",
      "Speed: 3.0ms preprocess, 175.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 189.0ms\n",
      "Speed: 2.4ms preprocess, 189.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 209.0ms\n",
      "Speed: 0.0ms preprocess, 209.0ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 181.4ms\n",
      "Speed: 3.5ms preprocess, 181.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 141.9ms\n",
      "Speed: 1.7ms preprocess, 141.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 162.8ms\n",
      "Speed: 4.8ms preprocess, 162.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 146.7ms\n",
      "Speed: 5.3ms preprocess, 146.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 169.1ms\n",
      "Speed: 2.7ms preprocess, 169.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 158.7ms\n",
      "Speed: 2.0ms preprocess, 158.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 140.0ms\n",
      "Speed: 3.0ms preprocess, 140.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 141.4ms\n",
      "Speed: 2.4ms preprocess, 141.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 159.1ms\n",
      "Speed: 3.1ms preprocess, 159.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 170.6ms\n",
      "Speed: 2.8ms preprocess, 170.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 194.8ms\n",
      "Speed: 2.0ms preprocess, 194.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 198.9ms\n",
      "Speed: 0.6ms preprocess, 198.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 149.6ms\n",
      "Speed: 2.0ms preprocess, 149.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 140.4ms\n",
      "Speed: 3.3ms preprocess, 140.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 164.5ms\n",
      "Speed: 0.0ms preprocess, 164.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 143.9ms\n",
      "Speed: 3.1ms preprocess, 143.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 3 persons, 195.9ms\n",
      "Speed: 3.4ms preprocess, 195.9ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 186.5ms\n",
      "Speed: 4.0ms preprocess, 186.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 159.1ms\n",
      "Speed: 1.2ms preprocess, 159.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 180.8ms\n",
      "Speed: 3.0ms preprocess, 180.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 150.7ms\n",
      "Speed: 2.2ms preprocess, 150.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 154.5ms\n",
      "Speed: 3.1ms preprocess, 154.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 156.8ms\n",
      "Speed: 2.6ms preprocess, 156.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 159.0ms\n",
      "Speed: 1.6ms preprocess, 159.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 155.1ms\n",
      "Speed: 2.4ms preprocess, 155.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 147.4ms\n",
      "Speed: 0.0ms preprocess, 147.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 172.8ms\n",
      "Speed: 2.7ms preprocess, 172.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 155.3ms\n",
      "Speed: 4.5ms preprocess, 155.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 152.2ms\n",
      "Speed: 3.6ms preprocess, 152.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 188.0ms\n",
      "Speed: 2.6ms preprocess, 188.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 188.7ms\n",
      "Speed: 4.0ms preprocess, 188.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 226.5ms\n",
      "Speed: 3.0ms preprocess, 226.5ms inference, 7.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 181.0ms\n",
      "Speed: 2.3ms preprocess, 181.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 174.2ms\n",
      "Speed: 2.8ms preprocess, 174.2ms inference, 10.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 176.9ms\n",
      "Speed: 4.0ms preprocess, 176.9ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 196.7ms\n",
      "Speed: 3.5ms preprocess, 196.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 195.5ms\n",
      "Speed: 6.2ms preprocess, 195.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 188.4ms\n",
      "Speed: 2.8ms preprocess, 188.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 188.9ms\n",
      "Speed: 3.0ms preprocess, 188.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 176.0ms\n",
      "Speed: 5.6ms preprocess, 176.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 188.3ms\n",
      "Speed: 3.1ms preprocess, 188.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 3 persons, 174.7ms\n",
      "Speed: 3.0ms preprocess, 174.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 185.0ms\n",
      "Speed: 0.0ms preprocess, 185.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 177.8ms\n",
      "Speed: 2.6ms preprocess, 177.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 3 persons, 221.5ms\n",
      "Speed: 5.3ms preprocess, 221.5ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 185.9ms\n",
      "Speed: 2.6ms preprocess, 185.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 200.7ms\n",
      "Speed: 2.8ms preprocess, 200.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 170.9ms\n",
      "Speed: 4.9ms preprocess, 170.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 141.0ms\n",
      "Speed: 3.0ms preprocess, 141.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 158.4ms\n",
      "Speed: 0.4ms preprocess, 158.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 3 persons, 160.0ms\n",
      "Speed: 2.0ms preprocess, 160.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 3 persons, 142.6ms\n",
      "Speed: 2.0ms preprocess, 142.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 3 persons, 141.3ms\n",
      "Speed: 2.0ms preprocess, 141.3ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 165.8ms\n",
      "Speed: 4.7ms preprocess, 165.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 154.8ms\n",
      "Speed: 3.4ms preprocess, 154.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 180.4ms\n",
      "Speed: 1.4ms preprocess, 180.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 193.9ms\n",
      "Speed: 3.5ms preprocess, 193.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 171.0ms\n",
      "Speed: 2.2ms preprocess, 171.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 166.0ms\n",
      "Speed: 2.4ms preprocess, 166.0ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 205.3ms\n",
      "Speed: 3.5ms preprocess, 205.3ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 3 persons, 193.3ms\n",
      "Speed: 2.7ms preprocess, 193.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 3 persons, 192.4ms\n",
      "Speed: 2.5ms preprocess, 192.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 190.0ms\n",
      "Speed: 1.8ms preprocess, 190.0ms inference, 5.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 183.2ms\n",
      "Speed: 2.9ms preprocess, 183.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 205.8ms\n",
      "Speed: 2.6ms preprocess, 205.8ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 201.4ms\n",
      "Speed: 3.9ms preprocess, 201.4ms inference, 14.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 179.7ms\n",
      "Speed: 5.2ms preprocess, 179.7ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 186.0ms\n",
      "Speed: 3.0ms preprocess, 186.0ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 190.3ms\n",
      "Speed: 4.5ms preprocess, 190.3ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 180.8ms\n",
      "Speed: 3.3ms preprocess, 180.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 203.3ms\n",
      "Speed: 2.2ms preprocess, 203.3ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 193.3ms\n",
      "Speed: 2.6ms preprocess, 193.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 197.5ms\n",
      "Speed: 3.0ms preprocess, 197.5ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 156.1ms\n",
      "Speed: 2.3ms preprocess, 156.1ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 204.2ms\n",
      "Speed: 3.1ms preprocess, 204.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 178.6ms\n",
      "Speed: 3.5ms preprocess, 178.6ms inference, 5.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 178.2ms\n",
      "Speed: 3.5ms preprocess, 178.2ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 3 persons, 201.1ms\n",
      "Speed: 3.0ms preprocess, 201.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 208.3ms\n",
      "Speed: 2.0ms preprocess, 208.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 161.0ms\n",
      "Speed: 2.6ms preprocess, 161.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 169.0ms\n",
      "Speed: 2.3ms preprocess, 169.0ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 194.2ms\n",
      "Speed: 3.2ms preprocess, 194.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 201.8ms\n",
      "Speed: 2.7ms preprocess, 201.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 159.6ms\n",
      "Speed: 2.0ms preprocess, 159.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 166.7ms\n",
      "Speed: 2.0ms preprocess, 166.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\alexa\\runs\\pose\\predict2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = YOLO('yolov8n-pose.pt')\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while( cap.isOpened):\n",
    "    success, frame = cap.read()\n",
    "\n",
    "    if success:\n",
    "        results = model(frame, save=True)\n",
    "        annotated_frame = results[0].plot()\n",
    "        cv2.imshow('Yolo', annotated_frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ef958f-2286-4d08-9738-e7ffd2059b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3285d748-5468-4143-92ee-e0aad16782a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ce854a-afa1-468e-b79f-1c3a27ad9c67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b454eda-e781-4e71-8865-6b270eda98b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
